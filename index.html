<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>S²-Guidance Project</title>
    <link rel="stylesheet" href="style.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@700&family=Source+Serif+Pro:wght@400;700&display=swap" rel="stylesheet">
</head>
<body>

    <!-- ====================================================== -->
    <!-- 1. 全屏英雄区域 (新结构) -->
    <!-- ====================================================== -->
    <header class="hero-section">
        <!-- 背景大文字 -->
        <h1 class="hero-title-bg">S²-GUIDANCE</h1>

        <div class="content-wrapper">
            <!-- 标题 -->
            <h2 class="paper-title">
                Stochastic Self-Guidance for Training-Free Enhancement of Diffusion Models
            </h2>

            <!-- 作者和机构信息 -->
            <div class="author-section">
                <div class="authors">
                    <p class="author-line">
                        <span>Chubin Chen<sup>1,2,*</sup></span>
                        <span>Jiashu Zhu<sup>2</sup></span>
                        <span>Xiaokun Feng<sup>2,3</sup></span>
                        <span>Nisha Huang<sup>1</sup></span>
                    </p>
                    <p class="author-line">
                        <span>Meiqi Wu<sup>2,3</sup></span>
                        <span>Fangyuan Mao<sup>2</sup></span>
                        <span>Jiahong Wu<sup>2,‡</sup></span>
                        <span>Xiangxiang Chu<sup>2</sup></span>
                        <span>Xiu Li<sup>1,†</sup></span>
                    </p>
                </div>
                <div class="affiliations">
                    <p>
                        <sup>1</sup>Tsinghua University &nbsp;&nbsp;&nbsp;
                        <sup>2</sup>AMAP, Alibaba Group &nbsp;&nbsp;&nbsp;
                        <sup>3</sup>CASIA
                    </p>
                </div>
            </div>

            <!-- 备注信息 -->
            <div class="notes-section">
                <p>
                    <sup>*</sup>Work done during the internship at AMAP, Alibaba Group. &nbsp;&nbsp;
                    <sup>†</sup>Corresponding author. &nbsp;&nbsp;
                    <sup>‡</sup>Project lead.
                </p>
            </div>
            
            <!-- 按钮 -->
            <nav class="button-container">
                <a href="https://arxiv.org/abs/2312.01323" class="action-button">📄 Research Paper</a>
                <a href="https://github.com/chubin-chen/S2-Guidance" class="action-button">💻 GitHub</a>
            </nav>
        </div>
    </header>

    <!-- ====================================================== -->
    <!-- 2. 主内容滚动区域 (新结构) -->
    <!-- ====================================================== -->
    <main class="main-content">
        <!-- 摘要 (Abstract) 区域 -->
        <div class="section" id="abstract">
            <div class="content-wrapper">
                <h2 class="section-title">Abstract</h2>
                <p class="section-text">
                    Classifier-Free Guidance (CFG) is a widely used technique in modern diffusion models for enhancing sample quality and prompt adherence. However, through an empirical analysis on Gaussian mixture modeling with a closed-form solution, we observe a discrepancy between the suboptimal results produced by CFG and the ground truth. The model's excessive reliance on these suboptimal predictions often leads to semantic incoherence and low-quality outputs. To address this issue, we first empirically demonstrate that the model's suboptimal predictions can be effectively refined using sub-networks of the model itself. Building on this insight, we propose <strong>S<sup>2</sup>-Guidance</strong>, a novel method that leverages stochastic block-dropping during the forward process to construct sub-networks, effectively guiding the model away from potential low-quality predictions and toward high-quality outputs. Extensive qualitative and quantitative experiments on text-to-image and text-to-video generation tasks demonstrate that <strong>S<sup>2</sup>-Guidance</strong> delivers superior performance, consistently surpassing CFG and other advanced guidance strategies. Our code will be released.
                </p>
            </div>
        </div>

        <!-- 方法 (Method) 区域 -->
        <div class="section" id="method">
            <div class="content-wrapper">
                <h2 class="section-title">Method</h2>
                <p class="section-text">
                    Our method, S²-Guidance, operates by injecting noise into intermediate feature maps of the diffusion model's U-Net and then using the model's own denoising capabilities to predict a "cleaner" version of those features. The difference between the original and the cleaner features serves as a guidance signal, steering the overall generation process towards more refined results. The diagram below illustrates the core mechanism.
                </p>
                <img src="assets/method_overview.png" alt="Method Overview Diagram" class="method-image">
            </div>
        </div>

        <!-- 画廊 (Gallery) 区域 -->
        <div class="section" id="gallery">
            <div class="content-wrapper">
                <h2 class="section-title">Gallery</h2>
                <!-- 图片展示子区域 -->
                <h3 class="subsection-title">Image Results</h3>
                <div class="gallery-grid">
                    <div class="gallery-item">
                        <img src="assets/image_result_1.jpg" alt="Generated Image 1">
                        <p class="caption">A highly detailed castle in a mystical forest.</p>
                    </div>
                    <div class="gallery-item">
                        <img src="assets/image_result_2.jpg" alt="Generated Image 2">
                        <p class="caption">Photorealistic portrait with expressive lighting.</p>
                    </div>
                </div>
                <!-- 视频展示子区域 -->
                <h3 class="subsection-title">Video Results</h3>
                <div class="gallery-grid">
                    <div class="gallery-item">
                        <video autoplay loop muted playsinline width="100%">
                            <source src="assets/video_result_1.mp4" type="video/mp4">
                        </video>
                        <p class="caption">Dynamic video generation showcasing temporal consistency.</p>
                    </div>
                    <div class="gallery-item">
                        <video autoplay loop muted playsinline width="100%">
                            <source src="assets/video_result_2.mp4" type="video/mp4">
                        </video>
                        <p class="caption">An evolving abstract animation with fluid motion.</p>
                    </div>
                </div>
            </div>
        </div>
    </main>

</body>
</html>
